{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPIOlnTK-SZs"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA0eYTiC-Hzz"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHIhOmU0Nual"
      },
      "outputs": [],
      "source": [
        "# View dataset\n",
        "%cd \"/content/drive/Shareddrives/CS152 Project/dataset/text\"\n",
        "MY_FOLDER_PATH = \"/content/drive/Shareddrives/CS152 Project/dataset/text/\"\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwL9do2uBAQE"
      },
      "outputs": [],
      "source": [
        "# Packages to Install\n",
        "!pip install -q google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNiqAsY6DfyE"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from google.genai import Client\n",
        "from google.genai.types import CreateBatchJobConfig\n",
        "from datetime import datetime\n",
        "import fsspec\n",
        "import time\n",
        "from google.colab import auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOqb1l9jL8Bz"
      },
      "outputs": [],
      "source": [
        "# Auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHksFnIbB73W"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"xxxx\" # Configure API Key - replace \"xxxx\" with our API key, contact Andrea for access if you need it\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kpag1d9B2TL"
      },
      "source": [
        "# Basic Text Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onRmg4BYD6qp"
      },
      "outputs": [],
      "source": [
        "# AI Text Detection PROMPT\n",
        "\n",
        "PROMPT = \"\"\"\n",
        "You're an expert in detecting AI-generated content, especially social media captions or prompts used to generate images with tools like DALL·E, Midjourney, Imagen, or Stable Diffusion.\n",
        "\n",
        "Analyze the caption below and determine if it contains any of the following:\n",
        "- A prompt-like structure (e.g., \"portrait of a girl in ultra HD\", \"3D render of...\")\n",
        "- Mentions of generative AI tools or hashtags (e.g., #dalle2, #midjourney, #stablediffusion)\n",
        "- Language that appears to be describing an AI-generated image (not a personal experience)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Output Format**\n",
        "\n",
        "Classification: [0 / 1 / Don't know]\n",
        "- 0 = Human-written, non-AI-related caption\n",
        "- 1 = Likely associated with AI-generated content\n",
        "- Don't know = Caption is ambiguous or lacks clear indicators\n",
        "\n",
        "Confidence Score: [X]%\n",
        "- Provide a percentage (0-100%) indicating your confidence in the binary classification.\n",
        "\n",
        "Brief Justification:\n",
        "- In 2–3 concise sentences, explain the most significant reasons for your classification. Focus on structural, linguistic, or hashtag clues. Do not just restate the task description.\n",
        "\n",
        "---\n",
        "\n",
        "**Important Guidance**:\n",
        "- If confidence is low or evidence is unclear, prefer “Don't know”.\n",
        "- Weigh multiple subtle AI indicators more strongly than a single obvious one.\n",
        "- Be cautious: some real captions may use odd phrasing without being AI-related.\n",
        "- Prioritize linguistic patterns, keyword usage, and formatting common in AI prompts.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L25UwuhdIR-i"
      },
      "source": [
        "# Batch Job Input (df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiDUqSxjOOnN"
      },
      "outputs": [],
      "source": [
        "# Load df\n",
        "csv_path = MY_FOLDER_PATH + \"df_text_for_llm.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "df = df.dropna(subset=[\"body\"])\n",
        "captions = df[\"body\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuCeS9X_IcbJ"
      },
      "outputs": [],
      "source": [
        "records = [\n",
        "    {\n",
        "        \"request\": {\n",
        "            \"contents\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"parts\": [\n",
        "                        {\"text\": f\"{PROMPT}\\n\\nCaption:\\n\\\"\\\"\\\"{caption}\\\"\\\"\\\"\"}\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            \"generationConfig\": {\n",
        "                \"temperature\": 0.4\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    for caption in captions\n",
        "]\n",
        "\n",
        "with open(\"text_requests.jsonl\", \"w\", encoding=\"utf-8\") as fout:\n",
        "    for rec in records:\n",
        "        fout.write(json.dumps(rec))\n",
        "        fout.write(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d3PxoNCIlhs"
      },
      "outputs": [],
      "source": [
        "!gsutil -m cp text_requests.jsonl gs://cs152_text/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t5mMWEgKtO0"
      },
      "outputs": [],
      "source": [
        "client = Client(vertexai=True, project=\"gen-lang-client-0780203024\", location=\"us-central1\")\n",
        "\n",
        "INPUT_DATA = \"gs://cs152_text/text_requests.jsonl\"\n",
        "BUCKET_URI = \"gs://cs152_text/text_output\"\n",
        "MODEL_ID = \"gemini-2.0-flash-001\"\n",
        "\n",
        "gcs_batch_job = client.batches.create(\n",
        "    model=MODEL_ID,\n",
        "    src=INPUT_DATA,\n",
        "    config=CreateBatchJobConfig(dest=BUCKET_URI),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffrECf-1tdLK"
      },
      "outputs": [],
      "source": [
        "while gcs_batch_job.state in [\"JOB_STATE_PENDING\", \"JOB_STATE_RUNNING\"]:\n",
        "    print(f\"Waiting... current job state: {gcs_batch_job.state}\")\n",
        "    time.sleep(10)\n",
        "    gcs_batch_job = client.batches.get(name=gcs_batch_job.name)\n",
        "\n",
        "print(f\"Job finished with state: {gcs_batch_job.state}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oc1tCeXwgmrX"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "fs = fsspec.filesystem(\"gcs\")\n",
        "\n",
        "file_paths = fs.glob(f\"{BUCKET_URI}/*/predictions.jsonl\")\n",
        "df_out = pd.read_json(f\"gs://{file_paths[-1]}\", lines=True)\n",
        "\n",
        "def extract_text_response(resp):\n",
        "    try:\n",
        "        return resp['candidates'][0]['content']['parts'][0]['text']\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "df_out['response_text'] = df_out['response'].apply(extract_text_response)\n",
        "\n",
        "df_out['Classification'] = df_out['response_text'].str.extract(r\"Classification:\\s*(\\[?\\d+|Don't know\\]?)\", expand=False).str.strip(\"[]\")\n",
        "df_out['Confidence'] = df_out['response_text'].str.extract(r'Confidence Score:\\s*\\[?(\\d+(?:\\.\\d+)?)%', expand=False)\n",
        "df_out['Justification'] = df_out['response_text'].str.extract(r'Brief Justification:\\s*(.*)', flags=re.DOTALL, expand=False).str.strip()\n",
        "\n",
        "df_out[['Classification', 'Confidence', 'Justification']].to_csv(\"text_with_gemini.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmqcQYQ3AYNm"
      },
      "source": [
        "# True Positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Leiur9iwAdiN"
      },
      "outputs": [],
      "source": [
        "# Reload both files to ensure clean merge\n",
        "text_csv_path = MY_FOLDER_PATH + \"df_text_for_llm.csv\"\n",
        "gemini_csv_path = MY_FOLDER_PATH + \"text_with_gemini.csv\"\n",
        "\n",
        "df_text = pd.read_csv(text_csv_path).dropna(subset=[\"body\"])\n",
        "df_gemini = pd.read_csv(gemini_csv_path)\n",
        "\n",
        "df_text = df_text.reset_index(drop=True)\n",
        "df_gemini = df_gemini.reset_index(drop=True)\n",
        "\n",
        "assert len(df_text) == len(df_gemini), \"Mismatch in rows between Gemini results and input text.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3kdt8azA_OK"
      },
      "outputs": [],
      "source": [
        "# Make a fresh copy to avoid modifying df_text directly\n",
        "df_merged = df_text.copy()\n",
        "\n",
        "# Add Gemini outputs\n",
        "df_merged[\"gemini_classification\"] = df_gemini[\"Classification\"]\n",
        "df_merged[\"gemini_confidence\"] = pd.to_numeric(df_gemini[\"Confidence\"], errors=\"coerce\")\n",
        "df_merged[\"gemini_justification\"] = df_gemini[\"Justification\"]\n",
        "\n",
        "df_merged[[\"body\", \"ai_service\", \"gemini_classification\", \"gemini_confidence\", \"gemini_justification\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zT_Fh_uwBMiM"
      },
      "outputs": [],
      "source": [
        "# Create true label: 1 if ai_service is present, 0 otherwise\n",
        "df_merged[\"is_ai\"] = df_merged[\"ai_service\"].notna().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vzEzaeKVBO1-"
      },
      "outputs": [],
      "source": [
        "# Convert Gemini output to numeric values\n",
        "df_merged[\"gemini_label\"] = df_merged[\"gemini_classification\"].map({\n",
        "    \"0\": 0,\n",
        "    \"1\": 1,\n",
        "    \"Don't know\": 0.5\n",
        "})\n",
        "\n",
        "# Filter to exclude \"Don't know\"\n",
        "df_eval = df_merged[df_merged[\"gemini_label\"] != 0.5].dropna(subset=[\"gemini_label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhMIu_MBBQ_1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = df_eval[\"is_ai\"]\n",
        "y_pred = df_eval[\"gemini_label\"].astype(int)\n",
        "\n",
        "# Print classification report\n",
        "print(\"=== Gemini vs. Ground Truth ===\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Human\", \"AI\"]))\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Human\", \"AI\"], yticklabels=[\"Human\", \"AI\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Gemini Text Classification Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEIvXsz-G59F"
      },
      "outputs": [],
      "source": [
        "# CSV to save\n",
        "merged_csv_path = MY_FOLDER_PATH + \"gemini_labeled_dataset.csv\"\n",
        "df_merged.to_csv(merged_csv_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
