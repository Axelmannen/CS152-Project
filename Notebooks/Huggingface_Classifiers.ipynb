{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is generates predictions from two of the top Deepfake detection models on Huggingface.  \n"
      ],
      "metadata": {
        "id": "Eq3PzFgfedUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Kw5faniZw92l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTQtobZ6w2uM"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "G91FQXzmxq0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Config\n",
        "DATASET_FOLDER_PATH = \"/content/drive/Shareddrives/CS152 Project/dataset/\"\n",
        "DATASET_TREE_PATH = \"/content/drive/Shareddrives/CS152 Project/dataset/all/\""
      ],
      "metadata": {
        "id": "B2asXoRLxz1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f\"{DATASET_FOLDER_PATH}train.csv\")\n",
        "test_df = pd.read_csv(f\"{DATASET_FOLDER_PATH}test.csv\")"
      ],
      "metadata": {
        "id": "cl6U0vHiyL49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_model_predictions(df, predict_function):\n",
        "\n",
        "  # Dataset includes leading slash, hence the [1:]\n",
        "  path_list = [os.path.join(DATASET_TREE_PATH, path[1:]) for path in df[\"Image Path\"]]\n",
        "\n",
        "  new_columns = predict_function(path_list)\n",
        "\n",
        "  for col_name, col_data in new_columns.items():\n",
        "    df[col_name] = col_data"
      ],
      "metadata": {
        "id": "VobTfdXUyTy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface Models"
      ],
      "metadata": {
        "id": "AAZ_fRot0oSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "!pip install -q transformers\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "m7a8rRoJxDZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dima806 model\n",
        "\n",
        "dima806_pipeline = pipeline(\"image-classification\", model=\"dima806/deepfake_vs_real_image_detection\")\n",
        "\n",
        "def predict_dima806(path_list):\n",
        "\n",
        "  all_predictions = dima806_pipeline(path_list)\n",
        "\n",
        "  predictions = []\n",
        "  for prediction_dicts in all_predictions:\n",
        "    for prediction_dict in prediction_dicts:\n",
        "      if prediction_dict[\"label\"] == \"Fake\":\n",
        "        predictions.append(prediction_dict[\"score\"])\n",
        "        break\n",
        "\n",
        "  assert len(predictions) == len(path_list)\n",
        "\n",
        "  # 1 is fake, 0 is real\n",
        "  return {\"dima806_score\": predictions}"
      ],
      "metadata": {
        "id": "nykpLWys1DJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wvolf model\n",
        "\n",
        "wvolf_pipeline = pipeline(\"image-classification\", model=\"Wvolf/ViT_Deepfake_Detection\")\n",
        "\n",
        "def predict_wvolf(path_list):\n",
        "\n",
        "  all_predictions = wvolf_pipeline(path_list)\n",
        "\n",
        "  predictions = []\n",
        "  for prediction_dicts in all_predictions:\n",
        "    for prediction_dict in prediction_dicts:\n",
        "      if prediction_dict[\"label\"] == \"Fake\":\n",
        "        predictions.append(prediction_dict[\"score\"])\n",
        "        break\n",
        "\n",
        "  assert len(predictions) == len(path_list)\n",
        "\n",
        "  # 1 is fake, 0 is real\n",
        "  return {\"wvolf_score\": predictions}"
      ],
      "metadata": {
        "id": "VYMyMUe04OUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run models"
      ],
      "metadata": {
        "id": "hYGvUKk15KKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df = train_df.copy()\n",
        "df = test_df.copy()\n",
        "\n",
        "# Use only a couple samples when testing\n",
        "# train_df = train_df.sample(10)"
      ],
      "metadata": {
        "id": "Ssw3OOb97AG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_model_predictions(df, predict_dima806)"
      ],
      "metadata": {
        "id": "5lyk8A1_5Mad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save new dataframe\n",
        "df.to_csv(os.path.join(DATASET_FOLDER_PATH, \"test_with_hugginface.csv\"), index=False)"
      ],
      "metadata": {
        "id": "59yBqPFLeqmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_model_predictions(df, predict_wvolf)"
      ],
      "metadata": {
        "id": "vXWFbRUCv9Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save new dataframe\n",
        "df.to_csv(os.path.join(DATASET_FOLDER_PATH, \"test_with_huggingface.csv\"), index=False)"
      ],
      "metadata": {
        "id": "sjoOYT40v_yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "GDWwHdh13JKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(df, column_name):\n",
        "  # Calculate eval metrics\n",
        "  true_positives = 0\n",
        "  false_positives = 0\n",
        "  true_negatives = 0\n",
        "  false_negatives = 0\n",
        "  for index, row in df.iterrows():\n",
        "    if row[\"is_ai\"] == 1 and row[column_name] > 0.5:\n",
        "      true_positives += 1\n",
        "    elif row[\"is_ai\"] == 1 and row[column_name] <= 0.5:\n",
        "      false_negatives += 1\n",
        "    elif row[\"is_ai\"] == 0 and row[column_name] > 0.5:\n",
        "      false_positives += 1\n",
        "    elif row[\"is_ai\"] == 0 and row[column_name] <= 0.5:\n",
        "      true_negatives += 1\n",
        "\n",
        "  assert true_positives + false_positives + true_negatives + false_negatives == len(df)\n",
        "\n",
        "  print(f\"Model: {column_name}\")\n",
        "  print(f\"Dataset size {len(df)}\")\n",
        "  print()\n",
        "  print(f\"True Positives: {true_positives}\")\n",
        "  print(f\"False Positives: {false_positives}\")\n",
        "  print(f\"True Negatives: {true_negatives}\")\n",
        "  print(f\"False Negatives: {false_negatives}\")\n",
        "  print()\n",
        "\n",
        "  accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
        "\n",
        "  if true_positives + false_positives == 0:\n",
        "    precision = 0\n",
        "  else:\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "  if true_positives + false_negatives == 0:\n",
        "    recall = 0\n",
        "  else:\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "  if precision + recall == 0:\n",
        "    f1_score = 0\n",
        "  else:\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "  print(f\"Precision: {precision}\")\n",
        "  print(f\"Recall: {recall}\")\n",
        "  print(f\"F1 Score: {f1_score}\")\n",
        "  print()\n",
        "  print()\n"
      ],
      "metadata": {
        "id": "crrBBTHR4tRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9S2Hkk_h1hxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataframe\n",
        "df = pd.read_csv(f\"{DATASET_FOLDER_PATH}/train_with_huggingface.csv\")\n",
        "\n",
        "# Filtering for looking at performance on subsets\n",
        "# filtered_rows = [index_row[1] for index_row in df.iterrows() if \"GAN\" in index_row[1][\"Image Path\"]]\n",
        "# filtered_rows = [index_row[1] for index_row in df.iterrows() if index_row[1][\"Skin Tone\"] > 8]\n",
        "# df = pd.DataFrame(filtered_rows)\n",
        "\n",
        "eval_model(df, \"dima806_score\")\n",
        "\n",
        "eval_model(df, \"wvolf_score\")"
      ],
      "metadata": {
        "id": "hHrbpORQ3HBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}