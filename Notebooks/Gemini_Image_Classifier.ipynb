{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foS81Eo5ONBi",
        "outputId": "2664ec8a-a255-4f27-b9db-956f2955d9b5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install google-genai --quiet\n",
        "from google import genai\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "import time\n",
        "import fsspec\n",
        "from google.cloud import bigquery\n",
        "from google.genai.types import CreateBatchJobConfig\n",
        "from google.genai.types import HttpOptions, Part\n",
        "import mimetypes\n",
        "import csv\n",
        "import json\n",
        "import ast\n",
        "from pathlib import Path\n",
        "import vertexai\n",
        "from vertexai.tuning import sft"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxagf2a1NzCz"
      },
      "source": [
        "#Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRHryn5o5hsS"
      },
      "outputs": [],
      "source": [
        "# Authenticate\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz3B97mYRkfU",
        "outputId": "4ded50af-dae4-4619-f077-2b1d4af852b3"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/drive/Shareddrives/CS152 Project/dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZWaUqAxrrFs",
        "outputId": "e80c33cd-36bf-48e8-a221-b27074a7ecb9"
      },
      "outputs": [],
      "source": [
        "# Initialize GCloud\n",
        "!curl https://sdk.cloud.google.com | bash\n",
        "!gcloud init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEPIWvAkrwOd",
        "outputId": "b4725414-f88f-4f87-9a67-600a47b592af"
      },
      "outputs": [],
      "source": [
        "# First copy all dataset images to Google Cloud bucket\n",
        "!gsutil -m cp -r \"/content/drive/Shareddrives/CS152 Project/dataset/all\" gs://cs152_images/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xxJ6hUAOW8b"
      },
      "outputs": [],
      "source": [
        "# A prompt which gives guidance on AI generation and asks detailed output\n",
        "\n",
        "normal = \"\"\"\n",
        "You are an expert digital forensics analyst trained in Professor Hany Farid's methodologies for detecting AI-generated faces. Analyze the provided facial image for signs of artificial generation.\n",
        "Examine the following categories systematically:\n",
        "1. Anatomical Integrity\n",
        "Count facial features (eyes, nostrils, ears, etc.) - are there duplicates or missing elements?\n",
        "Check for impossible anatomical configurations\n",
        "Verify natural placement and proportions of features\n",
        "Look for missing details (eyelashes, tear ducts, nasal hair, skin pores)\n",
        "2. Phenotypic Plausibility\n",
        "Assess if phenotypic combinations are statistically probable (e.g., skin tone vs. eye color)\n",
        "Check for impossible genetic combinations\n",
        "Verify age-appropriate features match across the face\n",
        "3. Geometric Consistency\n",
        "Analyze facial symmetry (natural faces are slightly asymmetric)\n",
        "Check perspective consistency across features\n",
        "Verify consistent facial landmark alignment\n",
        "Look for warping or morphing artifacts\n",
        "4. Texture and Detail Analysis\n",
        "Examine skin texture consistency and realism\n",
        "Check hair patterns for naturalness and consistent growth direction\n",
        "Verify consistent detail resolution across facial regions\n",
        "Look for smoothing or sharpening artifacts\n",
        "5. Ocular Examination\n",
        "Verify matching reflections in both eyes\n",
        "Check iris pattern complexity and uniqueness\n",
        "Examine pupil shape and size consistency\n",
        "Look for natural eye moisture and blood vessels\n",
        "6. Lighting and Shadow Coherence\n",
        "Verify consistent light source direction across all features\n",
        "Check shadow placement and softness\n",
        "Examine specular highlights for consistency\n",
        "Look for impossible lighting conditions\n",
        "7. Edge and Transition Analysis\n",
        "Examine face-to-background transitions\n",
        "Check for halo effects or unnatural boundaries\n",
        "Verify natural hair-to-skin transitions\n",
        "Look for copy-paste or blending artifacts\n",
        "\n",
        "Output Format:\n",
        "\n",
        "Classification: [0/1/Don't know]\n",
        "0 = Real/authentic face\n",
        "1 = AI-generated face\n",
        "Don't know = Insufficient information or ambiguous indicators\n",
        "Confidence Score: [X]% Provide a percentage (0-100%) indicating your confidence in the binary classification.\n",
        "\n",
        "Brief Justification: In 2-3 sentences, cite the most significant indicators that led to your classification. Keep this concise and do not just repeat my guidance above.\n",
        "Important Notes:\n",
        "If image quality is too low to make reliable assessments, output \"Don't know\"\n",
        "Weight multiple subtle anomalies more heavily than single obvious features\n",
        "Consider that some real faces may have unusual features due to medical conditions, cosmetic procedures, or rare genetics\n",
        "Focus on patterns consistent with known GAN, diffusion model, or other AI generation artifacts\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8zLlkM2Kv_6"
      },
      "outputs": [],
      "source": [
        "# A prompt which gives guidance on AI generation but asks for a binary classification\n",
        "\n",
        "normal_binary = \"\"\"\n",
        "You are an expert digital forensics analyst trained in Professor Hany Farid's methodologies for detecting AI-generated faces. Analyze the provided facial image for signs of artificial generation.\n",
        "Examine the following categories systematically:\n",
        "1. Anatomical Integrity\n",
        "Count facial features (eyes, nostrils, ears, etc.) - are there duplicates or missing elements?\n",
        "Check for impossible anatomical configurations\n",
        "Verify natural placement and proportions of features\n",
        "Look for missing details (eyelashes, tear ducts, nasal hair, skin pores)\n",
        "2. Phenotypic Plausibility\n",
        "Assess if phenotypic combinations are statistically probable (e.g., skin tone vs. eye color)\n",
        "Check for impossible genetic combinations\n",
        "Verify age-appropriate features match across the face\n",
        "3. Geometric Consistency\n",
        "Analyze facial symmetry (natural faces are slightly asymmetric)\n",
        "Check perspective consistency across features\n",
        "Verify consistent facial landmark alignment\n",
        "Look for warping or morphing artifacts\n",
        "4. Texture and Detail Analysis\n",
        "Examine skin texture consistency and realism\n",
        "Check hair patterns for naturalness and consistent growth direction\n",
        "Verify consistent detail resolution across facial regions\n",
        "Look for smoothing or sharpening artifacts\n",
        "5. Ocular Examination\n",
        "Verify matching reflections in both eyes\n",
        "Check iris pattern complexity and uniqueness\n",
        "Examine pupil shape and size consistency\n",
        "Look for natural eye moisture and blood vessels\n",
        "6. Lighting and Shadow Coherence\n",
        "Verify consistent light source direction across all features\n",
        "Check shadow placement and softness\n",
        "Examine specular highlights for consistency\n",
        "Look for impossible lighting conditions\n",
        "7. Edge and Transition Analysis\n",
        "Examine face-to-background transitions\n",
        "Check for halo effects or unnatural boundaries\n",
        "Verify natural hair-to-skin transitions\n",
        "Look for copy-paste or blending artifacts\n",
        "\n",
        "Output Format:\n",
        "\n",
        "Either \"0\" or \"1\", where \"0\" indicates the image is Real and \"1\" indicates the image is AI-Generated. Do NOT output anything else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pObIslX3d9iL"
      },
      "outputs": [],
      "source": [
        "# A short prompt which just asks for binary classification on the image task\n",
        "short = \"\"\"\n",
        "Analyze the provided facial image for signs of artificial generation.\n",
        "\n",
        "Output Format:\n",
        "\n",
        "Either \"0\" or \"1\", where \"0\" indicates the image is Real and \"1\" indicates the image is AI-Generated. Do NOT output anything else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCqJ2z6SrJCD"
      },
      "outputs": [],
      "source": [
        "# Load train, dev, or test dataset. Store prompt to use from above.\n",
        "\n",
        "dataset = \"train.csv\" # @param {type:\"string\"}\n",
        "df = pd.read_csv(dataset)\n",
        "prompt_type = \"long\" # @param [\"long\", \"long binary\", \"short binary\"] {type:\"string\"}\n",
        "if prompt_type == \"long\":\n",
        "  prompt = normal\n",
        "elif prompt_type == \"long binary\":\n",
        "  prompt = normal_binary\n",
        "else:\n",
        "  prompt = short"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OjqUEDZru7No",
        "outputId": "a4f741a4-16b4-47a3-b534-5ccb3786554a"
      },
      "outputs": [],
      "source": [
        "# Package inputs into JSON for batch-calling Gemini\n",
        "\n",
        "records = [\n",
        "    {\n",
        "        \"prompt\": prompt,\n",
        "        \"parts\": [\n",
        "            {\"fileUri\": \"gs://cs152_images/all\" + path},\n",
        "        ],\n",
        "    }\n",
        "    for path in df['Image Path']\n",
        "]\n",
        "\n",
        "\n",
        "OUTPUT_FILE = f\"requests_{prompt_type}_prompt.jsonl\"\n",
        "TEMPERATURE = 0.4\n",
        "\n",
        "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as fout:\n",
        "    for rec in records:\n",
        "        parts = [{\"text\": rec[\"prompt\"].strip()}]\n",
        "        for media in rec[\"parts\"]:\n",
        "            uri = media[\"fileUri\"]\n",
        "            mime, _ = mimetypes.guess_type(uri)\n",
        "            mime = mime or \"application/octet-stream\"\n",
        "            parts.append({\n",
        "                \"file_data\": {\n",
        "                    \"file_uri\": uri,\n",
        "                    \"mime_type\": mime\n",
        "                }\n",
        "            })\n",
        "        obj = {\n",
        "            \"request\": {\n",
        "                \"contents\": [\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"parts\": parts\n",
        "                    }\n",
        "                ],\n",
        "                \"generationConfig\": {\n",
        "                    \"temperature\": TEMPERATURE\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        fout.write(json.dumps(obj))\n",
        "        fout.write(\"\\n\")\n",
        "\n",
        "print(f\"Wrote {len(records)} requests to {OUTPUT_FILE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJnDD72-zbuq",
        "outputId": "3f3d69b7-de4b-461b-bb87-86e060857248"
      },
      "outputs": [],
      "source": [
        "# Send .json to Cloud\n",
        "!gsutil -m cp -r \"test_requests_short_prompt.jsonl\" gs://cs152_images/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxNL4EpUN8Sh"
      },
      "source": [
        "# Batch-call Gemini on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnf4WhO40BVt"
      },
      "outputs": [],
      "source": [
        "#Set Google Cloud details to use for batch-calls\n",
        "\n",
        "INPUT_DATA = \"gs://cs152_images/test_requests_short_prompt.jsonl\"  # @param {type:\"string\"}\n",
        "PROJECT_ID = \"gemini-deepfake-detection\"\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "BUCKET_URI = \"gs://cs152_test_output\"  # @param {type:\"string\"}\n",
        "MODEL_ID = \"gemini-2.0-flash-001\" # @param {type:\"string\"}\n",
        "\n",
        "if BUCKET_URI == \"[your-cloud-storage-bucket]\":\n",
        "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-{TIMESTAMP}\"\n",
        "\n",
        "    ! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NfB1ubF1tfx"
      },
      "outputs": [],
      "source": [
        "# Initialize Gemini client\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GCtU5X461BQo",
        "outputId": "c5e35a79-f1a6-46ea-bce5-819803699d80"
      },
      "outputs": [],
      "source": [
        "# Start a batch job on the dataset\n",
        "gcs_batch_job = client.batches.create(\n",
        "    model=MODEL_ID,\n",
        "    src=INPUT_DATA,\n",
        "    config=CreateBatchJobConfig(dest=BUCKET_URI),\n",
        ")\n",
        "gcs_batch_job.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwRhbIcu6Z_m",
        "outputId": "fc4766fe-c3d6-4361-9707-8d1b082cd647"
      },
      "outputs": [],
      "source": [
        "# Check all existing batch jobs\n",
        "for job in client.batches.list():\n",
        "    print(job.name, job.create_time, job.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbB54m-i6ACb",
        "outputId": "42f15a0a-253d-4045-9ec4-bd5b475d6760"
      },
      "outputs": [],
      "source": [
        "# Refresh the job until complete\n",
        "while gcs_batch_job.state == \"JOB_STATE_RUNNING\":\n",
        "    time.sleep(5)\n",
        "    print(f\"Job state: {gcs_batch_job.state}\")\n",
        "    gcs_batch_job = client.batches.get(name=gcs_batch_job.name)\n",
        "\n",
        "# Check if the job succeeds\n",
        "if gcs_batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
        "    print(\"Job succeeded!\")\n",
        "else:\n",
        "    print(f\"Job failed: {gcs_batch_job.error}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "T2stK-88S8Ed",
        "outputId": "fa6d8735-f73f-4a37-cd72-d219311496d9"
      },
      "outputs": [],
      "source": [
        "# Read the output json of batch job\n",
        "fs = fsspec.filesystem(\"gcs\")\n",
        "file_paths = fs.glob(f\"{gcs_batch_job.dest.gcs_uri}/*/predictions.jsonl\")\n",
        "if gcs_batch_job.state == \"JOB_STATE_SUCCEEDED\":\n",
        "  df = pd.read_json(f\"gs://{file_paths[-1]}\", lines=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdMdzCv-ayBB"
      },
      "outputs": [],
      "source": [
        "# The following 3 cells will extract the relevant results from the Gemini outputs\n",
        "\n",
        "def extract_response_text(resp):\n",
        "    try:\n",
        "        return resp['candidates'][0]['content']['parts'][0]['text']\n",
        "    except (KeyError, IndexError, TypeError):\n",
        "        return None\n",
        "\n",
        "# Keep the original function for extracting request text from the 'request' column\n",
        "def extract_request_text(req):\n",
        "    try:\n",
        "        # The structure is req -> contents[0] -> parts[1] -> file_data -> file_uri\n",
        "        return req['contents'][0]['parts'][1]['file_data']['file_uri']\n",
        "    except (KeyError, IndexError, TypeError):\n",
        "        return None\n",
        "\n",
        "df['response_text'] = df['response'].apply(extract_response_text)\n",
        "\n",
        "# 3. Now vectorize your three regex pulls over that new column:\n",
        "# Correct the column name from 'request_text' to 'request'\n",
        "df['Image Path'] = df['request'].apply(extract_request_text).str.lstrip(\"gs://cs152_images/all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqyNE5VXcEnY"
      },
      "outputs": [],
      "source": [
        "# In case of full prompt with justifications\n",
        "df['Classification'] = (\n",
        "    df['response_text'].str.extract(\n",
        "    r\"Classification:\\s*((?:\\[?\\d+\\]?|Don't know))\",\n",
        "    expand=False)\n",
        "    .str.strip(\"[]\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "WbtEjGQKcR6d",
        "outputId": "0b2f919e-c5e2-418e-86ea-072db696016d"
      },
      "outputs": [],
      "source": [
        "# In case of prompt with just 0/1\n",
        "df['Classification'] = df['response_text'].str.strip()\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRjFp-KPcHFO"
      },
      "outputs": [],
      "source": [
        "df['Confidence'] = df['response_text'].str.extract(\n",
        "    r'Confidence Score:\\s*\\[?([\\d]+(?:\\.\\d+)?)%\\]?',\n",
        "    expand=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys_j4n9HcIdV"
      },
      "outputs": [],
      "source": [
        "df['Justification'] = (\n",
        "    df['response_text']\n",
        "      .str.extract(r'Brief Justification:\\s*(.+)', flags=re.DOTALL, expand=False)\n",
        "      .str.strip()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRQS06BDDRsf"
      },
      "outputs": [],
      "source": [
        "# In case of prompt with confidence, justification\n",
        "cols_to_keep = ['Image Path', 'Classification', 'Confidence', 'Justification']\n",
        "df = df[cols_to_keep]\n",
        "#df.to_csv(\"train_with_gemini.csv\")\n",
        "df.to_csv(\"test_with_gemini_binary_prompt.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APRPskxnclUX"
      },
      "outputs": [],
      "source": [
        "cols_to_keep = ['Image Path', 'Classification']\n",
        "df = df[cols_to_keep]\n",
        "#df.to_csv(\"train_with_gemini.csv\")\n",
        "df.to_csv(\"test_with_gemini_short_prompt.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7M5fWHHoU_-V",
        "outputId": "32b493bd-e4db-4581-e849-4db3c233fb96"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKs6VP-A2yMf"
      },
      "outputs": [],
      "source": [
        "# Merge with  results from other models\n",
        "\n",
        "df_base = pd.read_csv('test_all_models.csv')\n",
        "df_results = pd.read_csv('test_with_gemini_short_prompt.csv')\n",
        "df_results['Image Path'] = '/' + df_results['Image Path'].astype(str)\n",
        "to_merge = df_results[['Image Path', 'Classification']]\n",
        "df_base_enriched = df_base.merge(\n",
        "    to_merge,\n",
        "    on='Image Path',\n",
        "    how='left'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "icW-OkuHJDB0",
        "outputId": "f6a993f7-4c44-4df5-aec8-ec1ce5334ffe"
      },
      "outputs": [],
      "source": [
        "df_base_enriched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CHOYf_TEoxb",
        "outputId": "c620e0cc-77a8-4b30-9b5f-77cd29e9ee36"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "n_missing = df_base_enriched['Classification'].isna().sum()\n",
        "n_missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "AGXHle95IfeB",
        "outputId": "7f7c79b7-e0d9-4415-adf2-974dd7f07a36"
      },
      "outputs": [],
      "source": [
        "# Do some cleanup of the new pd, then save (should have results from the model just batch-called)\n",
        "df_base_enriched = df_base_enriched.rename(columns={\"Classification\": \"Gemini Short-Prompt Classification\", \"Confidence\" : \"Gemini Confidence\", \"Justification\" : \"Gemini Justification\"})\n",
        "df_base_enriched['Gemini Classification'] = df_base_enriched['Gemini Classification'].replace(\"Don't know\", 0.5)\n",
        "df_base_enriched = df_base_enriched.dropna(subset=['Gemini Classification'])\n",
        "df_base_enriched.to_csv(\"test_all_models.csv\")\n",
        "df_base_enriched"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLBD0XavJ1q9"
      },
      "outputs": [],
      "source": [
        "# Define function to calculate eval metrics\n",
        "def eval_model(df, column_name):\n",
        "  # Calculate eval metrics\n",
        "  true_positives = 0\n",
        "  false_positives = 0\n",
        "  true_negatives = 0\n",
        "  false_negatives = 0\n",
        "  for index, row in df.iterrows():\n",
        "    pred = float(row[column_name])\n",
        "    if row[\"is_ai\"] == 1 and pred >= 0.5:\n",
        "      true_positives += 1\n",
        "    elif row[\"is_ai\"] == 1 and pred < 0.5:\n",
        "      false_negatives += 1\n",
        "    elif row[\"is_ai\"] == 0 and pred >= 0.5:\n",
        "      false_positives += 1\n",
        "    elif row[\"is_ai\"] == 0 and pred < 0.5:\n",
        "      true_negatives += 1\n",
        "\n",
        "  assert true_positives + false_positives + true_negatives + false_negatives == len(df)\n",
        "\n",
        "  print(f\"Model: {column_name}\")\n",
        "  print(f\"Dataset size {len(df)}\")\n",
        "  print()\n",
        "  print(f\"True Positives: {true_positives}\")\n",
        "  print(f\"False Positives: {false_positives}\")\n",
        "  print(f\"True Negatives: {true_negatives}\")\n",
        "  print(f\"False Negatives: {false_negatives}\")\n",
        "  print()\n",
        "\n",
        "  accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
        "\n",
        "  if true_positives + false_positives == 0:\n",
        "    precision = 0\n",
        "  else:\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "  if true_positives + false_negatives == 0:\n",
        "    recall = 0\n",
        "  else:\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "\n",
        "  if precision + recall == 0:\n",
        "    f1_score = 0\n",
        "  else:\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "  print(f\"Precision: {precision}\")\n",
        "  print(f\"Recall: {recall}\")\n",
        "  print(f\"F1 Score: {f1_score}\")\n",
        "  print()\n",
        "  print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-pzY6JUKIlI",
        "outputId": "eb897d86-0236-46eb-df3d-745366a24aa5"
      },
      "outputs": [],
      "source": [
        "train = False # @param {type:\"boolean\"}\n",
        "test = not train\n",
        "\n",
        "if train:\n",
        "  print(\"Performance on train: \\n\")\n",
        "  df_base_enriched = pd.read_csv(\"train_all_models_fixed.csv\")\n",
        "else:\n",
        "  print(\"Performance on test: \\n\")\n",
        "  df_base_enriched = pd.read_csv(\"test_all_models.csv\")\n",
        "\n",
        "eval_model(df_base_enriched, \"dima806_score\")\n",
        "eval_model(df_base_enriched, \"wvolf_score\")\n",
        "eval_model(df_base_enriched, \"Gemini Classification\")\n",
        "eval_model(df_base_enriched, \"Gemini Short-Prompt Classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROteokCs9lW_"
      },
      "source": [
        "# Supervised Fine-Tuning of Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiUHSVEKFNa3",
        "outputId": "de369a95-360f-4db3-9192-2b1a6c3be55c"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/drive/Shareddrives/CS152 Project/dataset/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3_pyRPi95m5",
        "outputId": "1744c3e3-6931-4a26-e6d8-67421e1ef351"
      },
      "outputs": [],
      "source": [
        "# Prepare train/val data, send to gCloud as .jsonl\n",
        "seed = 42\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "train_df = df.sample(frac=0.9, random_state=seed)\n",
        "val_df   = df.drop(train_df.index)\n",
        "print(len(train_df), len(val_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hwIz2bKO_CX"
      },
      "outputs": [],
      "source": [
        "# Define the prompt used for supervised fine-tuning\n",
        "# (This is the same as the long-binary prompt used earlier)\n",
        "prompt = \"\"\"\n",
        "You are an expert digital forensics analyst trained in Professor Hany Farid's methodologies for detecting AI-generated faces. Analyze the provided facial image for signs of artificial generation.\n",
        "Examine the following categories systematically:\n",
        "1. Anatomical Integrity\n",
        "Count facial features (eyes, nostrils, ears, etc.) - are there duplicates or missing elements?\n",
        "Check for impossible anatomical configurations\n",
        "Verify natural placement and proportions of features\n",
        "Look for missing details (eyelashes, tear ducts, nasal hair, skin pores)\n",
        "2. Phenotypic Plausibility\n",
        "Assess if phenotypic combinations are statistically probable (e.g., skin tone vs. eye color)\n",
        "Check for impossible genetic combinations\n",
        "Verify age-appropriate features match across the face\n",
        "3. Geometric Consistency\n",
        "Analyze facial symmetry (natural faces are slightly asymmetric)\n",
        "Check perspective consistency across features\n",
        "Verify consistent facial landmark alignment\n",
        "Look for warping or morphing artifacts\n",
        "4. Texture and Detail Analysis\n",
        "Examine skin texture consistency and realism\n",
        "Check hair patterns for naturalness and consistent growth direction\n",
        "Verify consistent detail resolution across facial regions\n",
        "Look for smoothing or sharpening artifacts\n",
        "5. Ocular Examination\n",
        "Verify matching reflections in both eyes\n",
        "Check iris pattern complexity and uniqueness\n",
        "Examine pupil shape and size consistency\n",
        "Look for natural eye moisture and blood vessels\n",
        "6. Lighting and Shadow Coherence\n",
        "Verify consistent light source direction across all features\n",
        "Check shadow placement and softness\n",
        "Examine specular highlights for consistency\n",
        "Look for impossible lighting conditions\n",
        "7. Edge and Transition Analysis\n",
        "Examine face-to-background transitions\n",
        "Check for halo effects or unnatural boundaries\n",
        "Verify natural hair-to-skin transitions\n",
        "Look for copy-paste or blending artifacts\n",
        "\n",
        "Output Format:\n",
        "\n",
        "Either \"0\" or \"1\", where \"0\" indicates the image is Real and \"1\" indicates the image is AI-Generated. Do NOT output anything else.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDX1xb3YNBZy"
      },
      "outputs": [],
      "source": [
        "# Prepare jsonl objects for train/val\n",
        "\n",
        "\n",
        "def df_to_gemini_jsonl(\n",
        "    df: pd.DataFrame,\n",
        "    out_path: str,\n",
        "    system_instruction: str | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Convert a DataFrame with image paths & labels to Gemini-SFT JSONL.\n",
        "    Each row becomes one line in `out_path`.\n",
        "    \"\"\"\n",
        "    # Build the systemInstruction once\n",
        "    sys_block = (\n",
        "        {\"role\": \"system\", \"parts\": [{\"text\": system_instruction}]}\n",
        "        if system_instruction\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for _, row in df.iterrows():\n",
        "            # ----- user message -----\n",
        "            mime_type = mimetypes.guess_type(row['Image Path'])[0]\n",
        "            mime_type = mime_type or \"application/octet-stream\"\n",
        "            user_msg = {\n",
        "                \"role\": \"user\",\n",
        "                \"parts\": [\n",
        "                    {\n",
        "                        \"fileData\": {\n",
        "                            \"mimeType\": mime_type,\n",
        "                            \"fileUri\": \"gs://cs152_images/all\" + row['Image Path'],\n",
        "                        }\n",
        "                    },\n",
        "                ],\n",
        "            }\n",
        "\n",
        "            # ----- label (model message) -----\n",
        "            model_msg = {\n",
        "                \"role\": \"model\",\n",
        "                \"parts\": [\n",
        "                    {\"text\": str(row['is_ai'])}\n",
        "                ],\n",
        "            }\n",
        "\n",
        "            record = {\"contents\": [user_msg, model_msg]}\n",
        "            if sys_block:\n",
        "                record[\"systemInstruction\"] = sys_block\n",
        "\n",
        "            json.dump(record, f, ensure_ascii=False)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(f\"âœ… Wrote {len(df)} examples to {out_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdaw3pU2OyBN",
        "outputId": "f376baec-5609-4708-9d2b-7069bedf8de1"
      },
      "outputs": [],
      "source": [
        "df_to_gemini_jsonl(\n",
        "    df=train_df,\n",
        "    out_path=\"train_requests.jsonl\",\n",
        "    system_instruction=prompt\n",
        ")\n",
        "df_to_gemini_jsonl(\n",
        "    df=val_df,\n",
        "    out_path=\"val_requests.jsonl\",\n",
        "    system_instruction=prompt\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoOgZbWZE8O-",
        "outputId": "9dec52c7-f464-445a-876b-f44f490838bc"
      },
      "outputs": [],
      "source": [
        "!gsutil -m cp -r \"/content/drive/Shareddrives/CS152 Project/dataset/val_requests.jsonl\" gs://cs152_finetuning/\n",
        "!gsutil -m cp -r \"/content/drive/Shareddrives/CS152 Project/dataset/train_requests.jsonl\" gs://cs152_finetuning/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "rdTTrGS49ov_",
        "outputId": "373e683e-9370-49d0-8f5f-6973e2aa4cf2"
      },
      "outputs": [],
      "source": [
        "# Start the fine-tuning job\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
        "\n",
        "sft_tuning_job = sft.train(\n",
        "    source_model=\"gemini-2.0-flash-001\",\n",
        "    train_dataset=\"gs://cs152_finetuning/train_requests.jsonl\",\n",
        "    validation_dataset=\"gs://cs152_finetuning/val_requests.jsonl\"\n",
        ")\n",
        "\n",
        "# Polling for job completion\n",
        "while not sft_tuning_job.has_ended:\n",
        "    time.sleep(60)\n",
        "    sft_tuning_job.refresh()\n",
        "\n",
        "print(sft_tuning_job.tuned_model_name)\n",
        "print(sft_tuning_job.tuned_model_endpoint_name)\n",
        "print(sft_tuning_job.experiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCqH4N3lAYYt",
        "outputId": "5b21ef30-f6ab-4d97-a2e6-ea339ecbb882"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/drive/Shareddrives/CS152 Project/dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dzPDb_81yrP",
        "outputId": "a5b11800-9170-47ff-91d8-38555d934f08"
      },
      "outputs": [],
      "source": [
        "# Call the fine-tuned model on the test dataset\n",
        "tuning_job_id = \"1732516294546161664\"\n",
        "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"), vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
        "tuning_job_name = f\"projects/{PROJECT_ID}/locations/{LOCATION}/tuningJobs/{tuning_job_id}\"\n",
        "tuning_job = client.tunings.get(name=tuning_job_name)\n",
        "text_classifications = []\n",
        "df = pd.read_csv(\"test_all_models.csv\")\n",
        "for _, row in tqdm(df.iterrows()):\n",
        "  file_uri = \"gs://cs152_images/all\" + row['Image Path']\n",
        "  response = client.models.generate_content(\n",
        "      model= tuning_job.tuned_model.endpoint,\n",
        "      contents=[Part.from_uri(\n",
        "            file_uri=file_uri,\n",
        "            mime_type=mimetypes.guess_type(row['Image Path'])[0],\n",
        "        ),\n",
        "        prompt]\n",
        "  )\n",
        "  text_classifications.append(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk5EuoJHFwQ1",
        "outputId": "f6427ccf-c088-4be1-bee3-07ef492e27bc"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "list(set(text_classifications))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox8dltiy64NT",
        "outputId": "3b9d18a7-4f71-4e69-9dc8-a042911f3328"
      },
      "outputs": [],
      "source": [
        "# Save predictions and evaluate the fine-tuned model\n",
        "df['Fine-Tuned Gemini Classification'] = text_classifications\n",
        "df.to_csv(\"test_with_finetuned_gemini.csv\")\n",
        "eval_model(df, \"Fine-Tuned Gemini Classification\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "qxagf2a1NzCz",
        "cxNL4EpUN8Sh",
        "ROteokCs9lW_"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
